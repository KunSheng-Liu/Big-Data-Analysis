{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# COVID-19 (Corona Virus Disease 2019)\n* Caused by a **SARS-COV-2** corona virus.  \n* First identified in **Wuhan, Hubei, China**. Earliest reported symptoms reported in **November 2019**. \n* First cases were linked to contact with the Huanan Seafood Wholesale Market, which sold live animals. \n* On **30 January** the WHO declared the outbreak to be a **Public Health Emergency of International Concern** ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as ani\n\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\nfrom plotly.subplots import make_subplots\nimport folium \nfrom folium import plugins\nfrom tqdm.notebook import tqdm as tqdm\n\n\nfrom pathlib import Path\ndata_dir = Path('../input/covid19-global-forecasting-week-1')\n\nimport os\nos.listdir(data_dir)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# HTML \nfrom IPython.display import HTML","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:06:25.465829Z","iopub.execute_input":"2022-01-09T08:06:25.466327Z","iopub.status.idle":"2022-01-09T08:06:29.889063Z","shell.execute_reply.started":"2022-01-09T08:06:25.466283Z","shell.execute_reply":"2022-01-09T08:06:29.887978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(data_dir/'train.csv',parse_dates=['Date'])\ndata.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-01-09T08:06:29.892305Z","iopub.execute_input":"2022-01-09T08:06:29.892815Z","iopub.status.idle":"2022-01-09T08:06:29.996702Z","shell.execute_reply.started":"2022-01-09T08:06:29.892746Z","shell.execute_reply":"2022-01-09T08:06:29.995578Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_data = pd.read_csv('../input/corona-virus-report/covid_19_clean_complete.csv', parse_dates=['Date'])\ncleaned_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:06:29.998666Z","iopub.execute_input":"2022-01-09T08:06:29.999155Z","iopub.status.idle":"2022-01-09T08:06:30.166901Z","shell.execute_reply.started":"2022-01-09T08:06:29.999087Z","shell.execute_reply":"2022-01-09T08:06:30.165795Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Day wise\n# ========\n\nday_wise = pd.read_csv('../input/corona-virus-report/day_wise.csv')\nday_wise['Date'] = pd.to_datetime(day_wise['Date'])\n# day_wise.set_index(\"Date\",inplace=True)\nday_wise.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:06:30.168706Z","iopub.execute_input":"2022-01-09T08:06:30.169493Z","iopub.status.idle":"2022-01-09T08:06:30.202057Z","shell.execute_reply.started":"2022-01-09T08:06:30.169431Z","shell.execute_reply":"2022-01-09T08:06:30.201104Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Cleaning Data","metadata":{}},{"cell_type":"code","source":"# cases \ncases = ['Confirmed', 'Deaths', 'Recovered', 'Active']\n\n# Active Case = confirmed - deaths - recovered\ncleaned_data['Active'] = cleaned_data['Confirmed'] - cleaned_data['Deaths'] - cleaned_data['Recovered']\n\n# filling missing values \ncleaned_data[['Province/State']] = cleaned_data[['Province/State']].fillna('')\ncleaned_data[cases] = cleaned_data[cases].fillna(0)\n\ncleaned_data.head()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-01-09T08:06:30.206339Z","iopub.execute_input":"2022-01-09T08:06:30.20666Z","iopub.status.idle":"2022-01-09T08:06:30.396016Z","shell.execute_reply.started":"2022-01-09T08:06:30.206618Z","shell.execute_reply":"2022-01-09T08:06:30.395014Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The cleaned data from [COVID-19 Complete Dataset (Updated every 24hrs)](https://www.kaggle.com/imdevskp/corona-virus-report) is used for visualizations.","metadata":{}},{"cell_type":"markdown","source":"**lets just see Confirmed , Deaths , Recovered abd Active in world wide in all over Country/Region and lets dig deeper into the top 5 Country/Region **","metadata":{}},{"cell_type":"code","source":"# Creating a dataframe with total no of cases for every country\nconfirmiedcases = pd.DataFrame(cleaned_data.groupby('Country/Region')['Confirmed'].sum())\nconfirmiedcases['Country/Region'] = confirmiedcases.index\nconfirmiedcases.index = np.arange(1,188)\n\nDeathcases = pd.DataFrame(cleaned_data.groupby('Country/Region')['Deaths'].sum())\nDeathcases['Country/Region'] = Deathcases.index\nDeathcases.iodex = np.arange(1,181)\n\nRecoveredcases = pd.DataFrame(cleaned_data.groupby('Country/Region')['Recovered'].sum())\nRecoveredcases['Country/Region'] = Recoveredcases.index\nRecoveredcases.iodex = np.arange(1,181)\n\nActivecases = pd.DataFrame(cleaned_data.groupby('Country/Region')['Active'].sum())\nActivecases['Country/Region'] = Activecases.index\nActivecases.iodex = np.arange(1,181)\n\nglobal_Activecases = Activecases[['Country/Region','Active']]\nglobal_Deathcases = Deathcases[['Country/Region','Deaths']]\nglobal_Recoveredcases = Recoveredcases[['Country/Region','Recovered']]\nglobal_confirmiedcases = confirmiedcases[['Country/Region','Confirmed']]\n\nfig = px.bar(global_confirmiedcases.sort_values('Confirmed',ascending=False)[:20][::-1],x='Confirmed',y='Country/Region',title='Confirmed Cases Worldwide',text='Confirmed', height=900, orientation='h')\nfig.show()\n\nfig = px.bar(global_Deathcases.sort_values('Deaths',ascending=False)[:20][::-1],x='Deaths',y='Country/Region',title='Deaths Cases Worldwide',text='Deaths', height=900, orientation='h')\nfig.show()\n\nfig = px.bar(global_Recoveredcases.sort_values('Recovered',ascending=False)[:20][::-1],x='Recovered',y='Country/Region',title='Recovered Cases Worldwide',text='Recovered', height=900, orientation='h')\nfig.show()\n\nfig = px.bar(global_Activecases.sort_values('Active',ascending=False)[:20][::-1],x='Active',y='Country/Region',title='Active Cases Worldwide',text='Active', height=900, orientation='h')\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:06:30.399891Z","iopub.execute_input":"2022-01-09T08:06:30.400459Z","iopub.status.idle":"2022-01-09T08:06:32.202387Z","shell.execute_reply.started":"2022-01-09T08:06:30.400244Z","shell.execute_reply":"2022-01-09T08:06:32.20146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\ncolor = ['#930000','#019858','#0066CC','#FFA042','#00CACA','#E1E100','#AFAF61','#9999CC']\n\nplt.xticks(rotation=30, ha=\"right\", rotation_mode=\"anchor\", fontsize=15) #rotate the x-axis values\n# plt.subplots_adjust(bottom = 0.2, top = 0.9) #ensuring the dates (on the x-axis) fit in the screen\nplt.ylabel('No of Cases', fontsize=15)\nplt.xlabel('Dates', fontsize=15)\n\ndef animate(i):\n    plt.legend([\"Confirmed\",\"Deaths\",\"Recovered\",\"Active\"],loc=\"upper left\")\n    line = plt.plot(day_wise[:i][\"Date\"],day_wise[[\"Confirmed\",\"Deaths\",\"Recovered\",\"Active\"]][:i].values)\n    for i in range(0,4):\n        line[i].set_color(color[i])\n    return line\n\nmyAnimation = ani.FuncAnimation(fig, animate,frames=np.arange(0,180,1),interval=10, blit=True,repeat=False)\n# animate(50)\nmyAnimation.save('myAnimation1.gif', writer='imagemagick', fps=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HTML('<img src=\"./myAnimation1.gif\" />')","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:07:57.042079Z","iopub.execute_input":"2022-01-09T08:07:57.042699Z","iopub.status.idle":"2022-01-09T08:07:57.050234Z","shell.execute_reply.started":"2022-01-09T08:07:57.042642Z","shell.execute_reply":"2022-01-09T08:07:57.049349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,10))\ncolor = ['#930000','#019858','#0066CC','#FFA042','#00CACA','#E1E100','#AFAF61','#9999CC']\n\nplt.ylabel('No of Deaths', fontsize=15)\nplt.xlabel('Dates', fontsize=15)\n\ndef animate(i):\n#     plt.legend([\"Confirmed\",\"Deaths\",\"Recovered\",\"Active\"],loc=\"upper right\")\n    ax.clear()\n    ax.pie(day_wise.iloc[i][2:5],labels=day_wise.columns[2:5],colors=color[1:4],autopct='%1.1f%%', textprops={'fontsize': 14})\n\n\nmyAnimation = ani.FuncAnimation(fig, animate,frames=np.arange(0,180,1),interval=10,repeat=False)\n\nmyAnimation.save('myAnimation2.gif', writer='imagemagick', fps=30)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:07:57.051708Z","iopub.execute_input":"2022-01-09T08:07:57.052041Z","iopub.status.idle":"2022-01-09T08:08:51.63007Z","shell.execute_reply.started":"2022-01-09T08:07:57.051988Z","shell.execute_reply":"2022-01-09T08:08:51.628949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HTML('<img src=\"./myAnimation2.gif\" />')","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:08:51.631944Z","iopub.execute_input":"2022-01-09T08:08:51.632404Z","iopub.status.idle":"2022-01-09T08:08:51.641166Z","shell.execute_reply.started":"2022-01-09T08:08:51.632349Z","shell.execute_reply":"2022-01-09T08:08:51.640141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**so by we can we can upderstand that**\n\n* china is the most Confirmed , Deaths , Recovered and having Active people as china is teh population and adter the COVID-19 by taking care they are now with most\n    Active people\n* followed by  Italy , Iran ,South Korea ,Spain in top 4 places and then the rest of the Countries \n* so lets make visualizations accordingly to the above result ","metadata":{}},{"cell_type":"markdown","source":"* the adove is visual is the Global Spread of the COVID-19 in all over time \n* the Comfirmed id cases are more than 350K and Deaths is more than 14K \n* the Recovered is more tha 100K and the active is nearly 200K","metadata":{}},{"cell_type":"markdown","source":"## Comparisions\n\n**How about comparing the cases to better assess the situation**","metadata":{}},{"cell_type":"code","source":"temp = cleaned_data.groupby('Date')['Recovered', 'Deaths', 'Active'].sum().reset_index()\ntemp = temp.melt(id_vars=\"Date\", value_vars=['Recovered', 'Deaths', 'Active'],\n                 var_name='case', value_name='count')\n\n\nfig = px.area(temp, x=\"Date\", y=\"count\", color='case',\n             title='Cases over time: Area Plot', color_discrete_sequence = ['cyan', 'red', 'orange'])\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:08:51.643047Z","iopub.execute_input":"2022-01-09T08:08:51.643902Z","iopub.status.idle":"2022-01-09T08:08:52.351108Z","shell.execute_reply.started":"2022-01-09T08:08:51.64384Z","shell.execute_reply":"2022-01-09T08:08:52.350244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Active cases rising up completely all together leaving recoveries way behind and deaths also staring to increase and might see a big rise if the trend continues.\n* China's recent recovery waves might be the reason for so much from this graph.","metadata":{}},{"cell_type":"markdown","source":"Taking China out of the equation to see the effects elsewhere.","metadata":{}},{"cell_type":"markdown","source":"## Mortality and Recovery Rates¶\n\n**It is worth seeing these stats as well. It might have a story for sure.**","metadata":{}},{"cell_type":"code","source":"cleaned_latest = cleaned_data[cleaned_data['Date'] == max(cleaned_data['Date'])]\nflg = cleaned_latest.groupby('Country/Region')['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()\n\nflg['mortalityRate'] = round((flg['Deaths']/flg['Confirmed'])*100, 2)\ntemp = flg[flg['Confirmed']>100]\ntemp = temp.sort_values('mortalityRate', ascending=False)\n\nfig = px.bar(temp.sort_values(by=\"mortalityRate\", ascending=False)[:10][::-1],\n             x = 'mortalityRate', y = 'Country/Region', \n             title='Deaths per 100 Confirmed Cases', text='mortalityRate', height=800, orientation='h',\n             color_discrete_sequence=['darkred']\n            )\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:08:52.352574Z","iopub.execute_input":"2022-01-09T08:08:52.352911Z","iopub.status.idle":"2022-01-09T08:08:52.920299Z","shell.execute_reply.started":"2022-01-09T08:08:52.352862Z","shell.execute_reply":"2022-01-09T08:08:52.919363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## COVID-19: Spread Over Time","metadata":{}},{"cell_type":"code","source":"formated_gdf = cleaned_data.groupby(['Date', 'Country/Region'])['Confirmed', 'Deaths'].max()\nformated_gdf = formated_gdf.reset_index()\nformated_gdf['Date'] = pd.to_datetime(formated_gdf['Date'])\nformated_gdf['Date'] = formated_gdf['Date'].dt.strftime('%m/%d/%Y')\nformated_gdf['size'] = formated_gdf['Confirmed'].pow(0.3)\n\nfig = px.choropleth(formated_gdf, locations=\"Country/Region\", locationmode='country names', \n                     color=\"Confirmed\", hover_name=\"Country/Region\", \n                     range_color= [0, 100000],height=800,\n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Spread Over Time', color_continuous_scale=\"portland\")\n# fig.update(layout_coloraxis_showscale=False)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:08:52.921871Z","iopub.execute_input":"2022-01-09T08:08:52.922244Z","iopub.status.idle":"2022-01-09T08:09:02.512265Z","shell.execute_reply.started":"2022-01-09T08:08:52.922194Z","shell.execute_reply":"2022-01-09T08:09:02.510785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling <a id=\"3\"></a>\n\nNow, I will demonstrate how sales can be forecasted using various methods, namely: **naive approach, moving average, Holt linear, ARIMA, and Prophet**\n\n## Train/Val split <a id=\"3.1\"></a>\n\nFirst, we need to create miniature training and validation sets to train and validate our models. I will take the last 30 days as the validation data and the 70 days before that as the training data. We need to predict the sales in the validation data using the sales in the training data.","metadata":{}},{"cell_type":"code","source":"train_dataset = pd.read_csv('../input/novel-corona-virus-2019-dataset/time_series_covid_19_confirmed.csv')\ndrop_clo = ['Province/State','Country/Region','Lat','Long']\ntrain_dataset=train_dataset.drop(drop_clo,axis=1).iloc[:,:70]\ndatewise= list(train_dataset.columns)\nval_dataset = train_dataset[datewise[-30:]]","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-09T08:09:02.514068Z","iopub.execute_input":"2022-01-09T08:09:02.514486Z","iopub.status.idle":"2022-01-09T08:09:02.638627Z","shell.execute_reply.started":"2022-01-09T08:09:02.51443Z","shell.execute_reply":"2022-01-09T08:09:02.637638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define plot function","metadata":{}},{"cell_type":"code","source":"def result_plot():\n    pred_1 = predictions[0]\n    pred_2 = predictions[1]\n    pred_3 = predictions[2]\n\n    fig = make_subplots(rows=3, cols=1)\n\n    fig.add_trace(\n        go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"),\n                   name=\"Train\"),\n        row=1, col=1\n    )\n\n    fig.add_trace(\n        go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines', marker=dict(color=\"darkorange\"),\n                   name=\"Val\"),\n        row=1, col=1\n    )\n\n    fig.add_trace(\n        go.Scatter(x=np.arange(70, 100), y=pred_1, mode='lines', marker=dict(color=\"seagreen\"),\n                   name=\"Pred\"),\n        row=1, col=1\n    )\n\n    fig.add_trace(\n        go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n        row=2, col=1\n    )\n\n    fig.add_trace(\n        go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n        row=2, col=1\n    )\n\n    fig.add_trace(\n        go.Scatter(x=np.arange(70, 100), y=pred_2, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n                   name=\"Denoised signal\"),\n        row=2, col=1\n    )\n\n    fig.add_trace(\n        go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n        row=3, col=1\n    )\n\n    fig.add_trace(\n        go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n        row=3, col=1\n    )\n\n    fig.add_trace(\n        go.Scatter(x=np.arange(70, 100), y=pred_3, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n                   name=\"Denoised signal\"),\n        row=3, col=1\n    )\n\n    fig.update_layout(height=1200, width=800, title_text=\"Naive approach\")\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:09:02.640668Z","iopub.execute_input":"2022-01-09T08:09:02.641064Z","iopub.status.idle":"2022-01-09T08:09:02.663695Z","shell.execute_reply.started":"2022-01-09T08:09:02.641006Z","shell.execute_reply":"2022-01-09T08:09:02.662831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Below are the sales from three sample data points. I will use these samples to demonstrate the working of the models.","metadata":{}},{"cell_type":"markdown","source":"**now we will see the Forcasting of all the important attribute like <font size=4 style=\"color:red\"> Confirmed</font>,<font size=4 style=\"color:red\"> Deaths</font>,<font size=4 style=\"color:red\"> Recovered</font> **","metadata":{}},{"cell_type":"markdown","source":"# time_series_covid_19_confirmed","metadata":{}},{"cell_type":"markdown","source":"**lets see the sample data points**","metadata":{}},{"cell_type":"code","source":"fig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"), showlegend=False,),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False,),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Train (blue) vs. Validation (orange) sales\")\nfig.show()","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-01-09T08:09:02.665207Z","iopub.execute_input":"2022-01-09T08:09:02.665774Z","iopub.status.idle":"2022-01-09T08:09:02.959401Z","shell.execute_reply.started":"2022-01-09T08:09:02.665728Z","shell.execute_reply":"2022-01-09T08:09:02.958328Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Naive approach <a id=\"3.2\"></a>\n\n\nThe first approach is the very simple **naive approach**. It simply forecasts the next day's sales as the current day's sales. The model can be summarized as:\n\n<img src=\"https://i.imgur.com/r8wjrzk.png\" width=\"120px\">\n\nIn the above equation, y<sub>t+1</sub> is the predicted value for the next day's sales and y<sub>t</sub> is today's sales. The model predicts tomorrow's sales as today's sales. Now let us see how this simple model performs on our miniature dataset. The training data is in <font color=\"blue\">blue</font>, validation data in <font color=\"darkorange\">orange</font>, and predictions in <font color=\"green\">green</font>.","metadata":{}},{"cell_type":"code","source":"predictions = []\nfor i in range(len(val_dataset.columns)):\n    if i == 0:\n        predictions.append(train_dataset[train_dataset.columns[-1]].values)\n    else:\n        predictions.append(val_dataset[val_dataset.columns[i-1]].values)\n    \npredictions = np.transpose(np.array([row.tolist() for row in predictions]))\nerror_naive = np.linalg.norm(predictions[:3] - val_dataset.values[:3])/len(predictions[0])","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-01-09T08:09:02.961373Z","iopub.execute_input":"2022-01-09T08:09:02.961848Z","iopub.status.idle":"2022-01-09T08:09:02.97555Z","shell.execute_reply.started":"2022-01-09T08:09:02.961783Z","shell.execute_reply":"2022-01-09T08:09:02.97413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_plot()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:09:02.979017Z","iopub.execute_input":"2022-01-09T08:09:02.979347Z","iopub.status.idle":"2022-01-09T08:09:03.319092Z","shell.execute_reply.started":"2022-01-09T08:09:02.979303Z","shell.execute_reply":"2022-01-09T08:09:03.318121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the forecasts made by the naive approach are not that accurate and it is to be expected of such a simple model. We need more complex models that use several time stamps to make forecasts.","metadata":{}},{"cell_type":"markdown","source":"## Moving average <a id=\"3.3\"></a>\n\nThe **moving average** method is more complex than the naive approach. It calculates the mean sales over the previous 30 days and forecasts that as the next day's sales. This method takes the previous 30 timesteps into consideration, and is therefore less prone to short term fluctuations than the naive approach. The model can be summarized as:\n\n<img src=\"https://i.imgur.com/5uJvt7H.png\" width=\"220px\">\n\nIn the above equation, y<sub>t+1</sub> is tomorrow's sales. On the right hand side, all the sales for the previous 30 days are added up and divided by 30 to find the average. This forms the model's prediction, y<sub>t+1</sub>. Now let us see how this new model performs on our miniature dataset. The training data is in <font color=\"blue\">blue</font>, validation data in <font color=\"darkorange\">orange</font>, and predictions in <font color=\"green\">green</font>.","metadata":{}},{"cell_type":"code","source":"predictions = []\nfor i in range(len(val_dataset.columns)):\n    if i == 0:\n        predictions.append(np.mean(train_dataset[train_dataset.columns[-30:]].values, axis=1))\n    if i < 31 and i > 0:\n        predictions.append(0.5 * (np.mean(train_dataset[train_dataset.columns[-30+i:]].values, axis=1) + \\\n                                  np.mean(predictions[:i], axis=0)))\n    if i > 31:\n        predictions.append(np.mean([predictions[:i]], axis=1))\n    \npredictions = np.transpose(np.array([row.tolist() for row in predictions]))\nerror_avg = np.linalg.norm(predictions[:3] - val_dataset.values[:3])/len(predictions[0])","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-01-09T08:09:03.320579Z","iopub.execute_input":"2022-01-09T08:09:03.320908Z","iopub.status.idle":"2022-01-09T08:09:03.369803Z","shell.execute_reply.started":"2022-01-09T08:09:03.320865Z","shell.execute_reply":"2022-01-09T08:09:03.368856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_plot()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:09:03.373065Z","iopub.execute_input":"2022-01-09T08:09:03.37352Z","iopub.status.idle":"2022-01-09T08:09:03.676221Z","shell.execute_reply.started":"2022-01-09T08:09:03.373453Z","shell.execute_reply":"2022-01-09T08:09:03.675325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Holt linear <a id=\"3.4\"></a>\n\nThe **Holt linear** is completely different from the first two methods. Holt linear attempts to capture the high-level trends in the time series data and fits the data with a straight line. The method can be summarized as follows:\n\n### Forecast, level, and trend equations respectively","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://i.imgur.com/MHgcgGo.png\" width=\"180px\">\n<img src=\"https://i.imgur.com/3ImRHEO.png\" width=\"300px\">\n<img src=\"https://i.imgur.com/XExnvMX.png\" width=\"300px\">\n\n\nIn the above equations, $\\alpha$ and $\\beta$ are constants which can be configured. The values *l<sub>t</sub>* and *b<sub>t</sub>* represent the **level** and **trend** values repsectively. The trend value is the slope of the linear forecast function and the level value is the *y*-intercept of the linear forecast function. The slope and *y*-intercept values are continuously updated using the second and third update equations. Finally, the slope and *y*-intercept are used to calculate the forecast *y<sub>t+h</sub>* (in equation 1), which is *h* time steps ahead of the current time step. Now let us see how this model performs on our miniature dataset. The training data is in <font color=\"blue\">blue</font>, validation data in <font color=\"darkorange\">orange</font>, and predictions in <font color=\"green\">green</font>.","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\npredictions = []\nfor row in tqdm(train_dataset[train_dataset.columns[-30:]].values[:3]):\n    fit = Holt(row).fit(smoothing_level = 0.3, smoothing_slope = 0.01)\n    predictions.append(fit.forecast(30))\npredictions = np.array(predictions).reshape((-1, 30))\nerror_holt = np.linalg.norm(predictions - val_dataset.values[:len(predictions)])/len(predictions[0])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:09:03.677755Z","iopub.execute_input":"2022-01-09T08:09:03.678161Z","iopub.status.idle":"2022-01-09T08:09:04.816105Z","shell.execute_reply.started":"2022-01-09T08:09:03.678105Z","shell.execute_reply":"2022-01-09T08:09:04.815074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_plot()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:09:04.817678Z","iopub.execute_input":"2022-01-09T08:09:04.818102Z","iopub.status.idle":"2022-01-09T08:09:05.129452Z","shell.execute_reply.started":"2022-01-09T08:09:04.81798Z","shell.execute_reply":"2022-01-09T08:09:05.128357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ARIMA <a id=\"3.6\"></a>\n\nAutoregressive integrated moving average (ARIMA) models were popularised by Box and Jenkins (1970). An ARIMA model describes a univariate time series as a combination of autoregressive (AR) and moving average (MA) lags which capture the autocorrelation within the time series. The order of integration denotes how many times the series has been differenced to obtain a stationary series.\n\nWe write an ARIMA(p,d,q) model for some time series data yt, where p is the number of autoregressive lags, d is the degree of differencing and q is the number of moving average lags as:\n\n![](https://www.machinelearningplus.com/wp-content/uploads/2019/02/Equation-3-min.png)\n\nARIMA models are associated with a Box-Jenkins approach to time series. According to this approach, you should difference the series until it is stationary, and then use information criteria and autocorrelation plots to choose the appropriate lag order for an ARIMA process. You then apply inference to obtain latent variable estimates, and check the model to see whether the model has captured the autocorrelation in the time series. For example, you can plot the autocorrelation of the model residuals. Once you are happy, you can use the model for retrospection and forecasting.","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\nfrom statsmodels.tsa.arima_model import ARIMA\n\npredictions = []\nfor row in tqdm(train_dataset[train_dataset.columns[-30:]].values[:3]):\n    fit = sm.tsa.statespace.SARIMAX(row, seasonal_order=(0, 1, 1, 7)).fit()\n    predictions.append(fit.forecast(30))\npredictions = np.array(predictions).reshape((-1, 30))\nerror_arima = np.linalg.norm(predictions[:3] - val_dataset.values[:3])/len(predictions[0])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:09:05.131342Z","iopub.execute_input":"2022-01-09T08:09:05.132111Z","iopub.status.idle":"2022-01-09T08:09:05.859791Z","shell.execute_reply.started":"2022-01-09T08:09:05.132049Z","shell.execute_reply":"2022-01-09T08:09:05.858917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_plot()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:09:05.861299Z","iopub.execute_input":"2022-01-09T08:09:05.861647Z","iopub.status.idle":"2022-01-09T08:09:06.835972Z","shell.execute_reply.started":"2022-01-09T08:09:05.861603Z","shell.execute_reply":"2022-01-09T08:09:06.834968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# time_series_covid_19_deaths","metadata":{}},{"cell_type":"markdown","source":"lets see sample data first to make the visual of the predictions better ","metadata":{}},{"cell_type":"code","source":"train_dataset = pd.read_csv('../input/novel-corona-virus-2019-dataset/time_series_covid_19_deaths.csv')\ndrop_clo = ['Province/State','Country/Region','Lat','Long']\ntrain_dataset=train_dataset.drop(drop_clo,axis=1).iloc[:,:70]\ndatewise= list(train_dataset.columns)\nval_dataset = train_dataset[datewise[-30:]]","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:09:06.837475Z","iopub.execute_input":"2022-01-09T08:09:06.83779Z","iopub.status.idle":"2022-01-09T08:09:06.954818Z","shell.execute_reply.started":"2022-01-09T08:09:06.837748Z","shell.execute_reply":"2022-01-09T08:09:06.953847Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"), showlegend=False,),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False,),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Train (blue) vs. Validation (orange) sales\")\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:09:06.957861Z","iopub.execute_input":"2022-01-09T08:09:06.958258Z","iopub.status.idle":"2022-01-09T08:09:07.276272Z","shell.execute_reply.started":"2022-01-09T08:09:06.958203Z","shell.execute_reply":"2022-01-09T08:09:07.27528Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Naive approach <a id=\"3.2\"></a>:","metadata":{}},{"cell_type":"code","source":"predictions = []\nfor i in range(len(val_dataset.columns)):\n    if i == 0:\n        predictions.append(train_dataset[train_dataset.columns[-1]].values)\n    else:\n        predictions.append(val_dataset[val_dataset.columns[i-1]].values)\n    \npredictions = np.transpose(np.array([row.tolist() for row in predictions]))\nerror_naive = np.linalg.norm(predictions[:3] - val_dataset.values[:3])/len(predictions[0])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:09:07.277894Z","iopub.execute_input":"2022-01-09T08:09:07.278273Z","iopub.status.idle":"2022-01-09T08:09:07.290305Z","shell.execute_reply.started":"2022-01-09T08:09:07.278221Z","shell.execute_reply":"2022-01-09T08:09:07.289263Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_plot()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:09:07.291546Z","iopub.execute_input":"2022-01-09T08:09:07.291848Z","iopub.status.idle":"2022-01-09T08:09:07.598844Z","shell.execute_reply.started":"2022-01-09T08:09:07.291806Z","shell.execute_reply":"2022-01-09T08:09:07.597946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Moving average <a id=\"3.3\"></a>:","metadata":{}},{"cell_type":"code","source":"predictions = []\nfor i in range(len(val_dataset.columns)):\n    if i == 0:\n        predictions.append(np.mean(train_dataset[train_dataset.columns[-30:]].values, axis=1))\n    if i < 31 and i > 0:\n        predictions.append(0.5 * (np.mean(train_dataset[train_dataset.columns[-30+i:]].values, axis=1) + \\\n                                  np.mean(predictions[:i], axis=0)))\n    if i > 31:\n        predictions.append(np.mean([predictions[:i]], axis=1))\n    \npredictions = np.transpose(np.array([row.tolist() for row in predictions]))\nerror_avg = np.linalg.norm(predictions[:3] - val_dataset.values[:3])/len(predictions[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:09:07.600096Z","iopub.execute_input":"2022-01-09T08:09:07.6004Z","iopub.status.idle":"2022-01-09T08:09:07.649155Z","shell.execute_reply.started":"2022-01-09T08:09:07.600343Z","shell.execute_reply":"2022-01-09T08:09:07.648231Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_plot()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:09:07.650313Z","iopub.execute_input":"2022-01-09T08:09:07.650611Z","iopub.status.idle":"2022-01-09T08:09:07.957888Z","shell.execute_reply.started":"2022-01-09T08:09:07.650577Z","shell.execute_reply":"2022-01-09T08:09:07.95678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Holt linear <a id=\"3.4\"></a>","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\npredictions = []\nfor row in tqdm(train_dataset[train_dataset.columns[-30:]].values[:3]):\n    fit = Holt(row).fit(smoothing_level = 0.3, smoothing_slope = 0.01)\n    predictions.append(fit.forecast(30))\npredictions = np.array(predictions).reshape((-1, 30))\nerror_holt = np.linalg.norm(predictions - val_dataset.values[:len(predictions)])/len(predictions[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:09:07.959568Z","iopub.execute_input":"2022-01-09T08:09:07.959898Z","iopub.status.idle":"2022-01-09T08:09:08.029385Z","shell.execute_reply.started":"2022-01-09T08:09:07.959847Z","shell.execute_reply":"2022-01-09T08:09:08.028295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_plot()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:09:08.036424Z","iopub.execute_input":"2022-01-09T08:09:08.036918Z","iopub.status.idle":"2022-01-09T08:09:08.543067Z","shell.execute_reply.started":"2022-01-09T08:09:08.03685Z","shell.execute_reply":"2022-01-09T08:09:08.541834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ARIMA <a id=\"3.4\"></a>","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\nfrom statsmodels.tsa.arima_model import ARIMA\n\npredictions = []\nfor row in tqdm(train_dataset[train_dataset.columns[-30:]].values[:3]):\n    fit = sm.tsa.statespace.SARIMAX(row, seasonal_order=(0, 1, 1, 7)).fit()\n    predictions.append(fit.forecast(30))\npredictions = np.array(predictions).reshape((-1, 30))\nerror_arima = np.linalg.norm(predictions[:3] - val_dataset.values[:3])/len(predictions[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:09:08.545172Z","iopub.execute_input":"2022-01-09T08:09:08.545655Z","iopub.status.idle":"2022-01-09T08:09:08.827416Z","shell.execute_reply.started":"2022-01-09T08:09:08.545587Z","shell.execute_reply":"2022-01-09T08:09:08.826221Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_plot()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:09:08.829321Z","iopub.execute_input":"2022-01-09T08:09:08.829789Z","iopub.status.idle":"2022-01-09T08:09:09.14253Z","shell.execute_reply.started":"2022-01-09T08:09:08.829721Z","shell.execute_reply":"2022-01-09T08:09:09.141618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# time_series_covid_19_recovered","metadata":{}},{"cell_type":"markdown","source":"lets see sample data first to make the visual of the predictions better ","metadata":{}},{"cell_type":"code","source":"train_dataset = pd.read_csv('../input/novel-corona-virus-2019-dataset/time_series_covid_19_recovered.csv')\ndrop_clo = ['Province/State','Country/Region','Lat','Long']\ntrain_dataset=train_dataset.drop(drop_clo,axis=1).iloc[:,:70]\ndatewise= list(train_dataset.columns)\nval_dataset = train_dataset[datewise[-30:]]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:09:09.144009Z","iopub.execute_input":"2022-01-09T08:09:09.144354Z","iopub.status.idle":"2022-01-09T08:09:09.250189Z","shell.execute_reply.started":"2022-01-09T08:09:09.144302Z","shell.execute_reply":"2022-01-09T08:09:09.249195Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"), showlegend=False,),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False,),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines+markers', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines+markers', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Train (blue) vs. Validation (orange) sales\")\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:09:09.251543Z","iopub.execute_input":"2022-01-09T08:09:09.251834Z","iopub.status.idle":"2022-01-09T08:09:09.547101Z","shell.execute_reply.started":"2022-01-09T08:09:09.251799Z","shell.execute_reply":"2022-01-09T08:09:09.546056Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Naive approach <a id=\"3.2\"></a>:","metadata":{}},{"cell_type":"code","source":"predictions = []\nfor i in range(len(val_dataset.columns)):\n    if i == 0:\n        predictions.append(train_dataset[train_dataset.columns[-1]].values)\n    else:\n        predictions.append(val_dataset[val_dataset.columns[i-1]].values)\n    \npredictions = np.transpose(np.array([row.tolist() for row in predictions]))\nerror_naive = np.linalg.norm(predictions[:3] - val_dataset.values[:3])/len(predictions[0])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:09:09.54906Z","iopub.execute_input":"2022-01-09T08:09:09.549558Z","iopub.status.idle":"2022-01-09T08:09:09.562332Z","shell.execute_reply.started":"2022-01-09T08:09:09.549489Z","shell.execute_reply":"2022-01-09T08:09:09.561093Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_plot()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-01-09T08:09:09.563754Z","iopub.execute_input":"2022-01-09T08:09:09.564107Z","iopub.status.idle":"2022-01-09T08:09:10.043151Z","shell.execute_reply.started":"2022-01-09T08:09:09.564054Z","shell.execute_reply":"2022-01-09T08:09:10.04188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Moving average <a id=\"3.3\"></a>:","metadata":{}},{"cell_type":"code","source":"predictions = []\nfor i in range(len(val_dataset.columns)):\n    if i == 0:\n        predictions.append(np.mean(train_dataset[train_dataset.columns[-30:]].values, axis=1))\n    if i < 31 and i > 0:\n        predictions.append(0.5 * (np.mean(train_dataset[train_dataset.columns[-30+i:]].values, axis=1) + \\\n                                  np.mean(predictions[:i], axis=0)))\n    if i > 31:\n        predictions.append(np.mean([predictions[:i]], axis=1))\n    \npredictions = np.transpose(np.array([row.tolist() for row in predictions]))\nerror_avg = np.linalg.norm(predictions[:3] - val_dataset.values[:3])/len(predictions[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:09:10.045188Z","iopub.execute_input":"2022-01-09T08:09:10.045544Z","iopub.status.idle":"2022-01-09T08:09:10.09314Z","shell.execute_reply.started":"2022-01-09T08:09:10.045486Z","shell.execute_reply":"2022-01-09T08:09:10.092056Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_plot()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-09T08:09:10.095287Z","iopub.execute_input":"2022-01-09T08:09:10.096009Z","iopub.status.idle":"2022-01-09T08:09:10.397174Z","shell.execute_reply.started":"2022-01-09T08:09:10.095913Z","shell.execute_reply":"2022-01-09T08:09:10.396279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Holt linear <a id=\"3.4\"></a>","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\npredictions = []\nfor row in tqdm(train_dataset[train_dataset.columns[-30:]].values[:3]):\n    fit = Holt(row).fit(smoothing_level = 0.3, smoothing_slope = 0.01)\n    predictions.append(fit.forecast(30))\npredictions = np.array(predictions).reshape((-1, 30))\nerror_holt = np.linalg.norm(predictions - val_dataset.values[:len(predictions)])/len(predictions[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:09:10.398522Z","iopub.execute_input":"2022-01-09T08:09:10.398852Z","iopub.status.idle":"2022-01-09T08:09:10.459113Z","shell.execute_reply.started":"2022-01-09T08:09:10.398803Z","shell.execute_reply":"2022-01-09T08:09:10.458237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_plot()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:09:10.460769Z","iopub.execute_input":"2022-01-09T08:09:10.461096Z","iopub.status.idle":"2022-01-09T08:09:10.764364Z","shell.execute_reply.started":"2022-01-09T08:09:10.461049Z","shell.execute_reply":"2022-01-09T08:09:10.763282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ARIMA <a id=\"3.6\"></a>","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\nfrom statsmodels.tsa.arima_model import ARIMA\n\npredictions = []\nfor row in tqdm(train_dataset[train_dataset.columns[-30:]].values[:3]):\n    fit = sm.tsa.statespace.SARIMAX(row, seasonal_order=(0, 1, 1, 7)).fit()\n    predictions.append(fit.forecast(30))\npredictions = np.array(predictions).reshape((-1, 30))\nerror_arima = np.linalg.norm(predictions[:3] - val_dataset.values[:3])/len(predictions[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:09:10.766238Z","iopub.execute_input":"2022-01-09T08:09:10.766974Z","iopub.status.idle":"2022-01-09T08:09:10.994393Z","shell.execute_reply.started":"2022-01-09T08:09:10.766884Z","shell.execute_reply":"2022-01-09T08:09:10.993318Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_plot()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:09:10.995944Z","iopub.execute_input":"2022-01-09T08:09:10.996577Z","iopub.status.idle":"2022-01-09T08:09:11.474364Z","shell.execute_reply.started":"2022-01-09T08:09:10.996518Z","shell.execute_reply":"2022-01-09T08:09:11.473494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comparison with similar Disease","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/imdevskp/covid19-vs-sars-vs-mers-vs-ebola-vs-h1n1","metadata":{}},{"cell_type":"code","source":"full_latest_grouped = cleaned_data.groupby('Country/Region')['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()\nepidemics = pd.DataFrame({\n    'epidemic' : ['COVID-19', 'SARS', 'EBOLA', 'MERS', 'H1N1'],\n    'start_year' : [2019, 2003, 2014, 2012, 2009],\n    'end_year' : [2020, 2004, 2016, 2017, 2010],\n    'confirmed' : [full_latest_grouped['Confirmed'].sum(), 8096, 28646, 2494, 6724149],\n    'deaths' : [full_latest_grouped['Deaths'].sum(), 774, 11323, 858, 19654]\n})\n\nepidemics['mortality'] = round((epidemics['deaths']/epidemics['confirmed'])*100, 2)\n\nepidemics.head()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-01-09T08:09:11.475802Z","iopub.execute_input":"2022-01-09T08:09:11.476123Z","iopub.status.idle":"2022-01-09T08:09:11.511454Z","shell.execute_reply.started":"2022-01-09T08:09:11.476081Z","shell.execute_reply":"2022-01-09T08:09:11.510422Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = epidemics.melt(id_vars='epidemic', value_vars=['confirmed', 'deaths', 'mortality'],\n                      var_name='Case', value_name='Value')\n\nfig = px.bar(temp, x=\"epidemic\", y=\"Value\", color='epidemic', text='Value', facet_col=\"Case\",\n             color_discrete_sequence = px.colors.qualitative.Bold)\nfig.update_traces(textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.update_yaxes(showticklabels=False)\nfig.layout.yaxis2.update(matches=None)\nfig.layout.yaxis3.update(matches=None)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T08:09:11.512793Z","iopub.execute_input":"2022-01-09T08:09:11.513337Z","iopub.status.idle":"2022-01-09T08:09:12.085108Z","shell.execute_reply.started":"2022-01-09T08:09:11.513296Z","shell.execute_reply":"2022-01-09T08:09:12.084087Z"},"trusted":true},"execution_count":null,"outputs":[]}]}